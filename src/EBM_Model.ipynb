{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franek/Library/Caches/pypoetry/virtualenvs/alzheimer-s-disease-prediction-oDGSe6K4-py3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of ['alzheimers_disease_data.csv']\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rabieelkharoua/alzheimers-disease-dataset\")\n",
    "files = os.listdir(path)\n",
    "print(\"Content of\", files)\n",
    "\n",
    "csv_file = files[0]\n",
    "csv_path = os.path.join(path, csv_file)\n",
    "\n",
    "# Load DataFrame\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Remove unnecessary columns\n",
    "df = df.drop(columns=[\"PatientID\", \"DoctorInCharge\"], errors=\"ignore\")\n",
    "\n",
    "# Splitting the data into features (X) and the target variable (Y)\n",
    "X = df.drop(columns=[\"Diagnosis\"])\n",
    "Y = df[\"Diagnosis\"]\n",
    "\n",
    "\n",
    "# Label encoding\n",
    "def change_labels(X):\n",
    "    custom_labels = {\n",
    "        \"Gender\": [\"Male\", \"Female\"],\n",
    "        \"Ethnicity\": [\"Caucasian\", \"African American\", \"Asian\", \"Other\"],\n",
    "        \"EducationLevel\": [\"None\", \"High School\", \"Bachelor's\", \"Higher\"],\n",
    "        \"Smoking\": [\"No\", \"Yes\"],\n",
    "        \"FamilyHistoryAlzheimers\": [\"No\", \"Yes\"],\n",
    "        \"CardiovascularDisease\": [\"No\", \"Yes\"],\n",
    "        \"Diabetes\": [\"No\", \"Yes\"],\n",
    "        \"Depression\": [\"No\", \"Yes\"],\n",
    "        \"HeadInjury\": [\"No\", \"Yes\"],\n",
    "        \"Hypertension\": [\"No\", \"Yes\"],\n",
    "        \"MemoryComplaints\": [\"No\", \"Yes\"],\n",
    "        \"BehavioralProblems\": [\"No\", \"Yes\"],\n",
    "        \"Confusion\": [\"No\", \"Yes\"],\n",
    "        \"Disorientation\": [\"No\", \"Yes\"],\n",
    "        \"PersonalityChanges\": [\"No\", \"Yes\"],\n",
    "        \"DifficultyCompletingTasks\": [\"No\", \"Yes\"],\n",
    "        \"Forgetfulness\": [\"No\", \"Yes\"],\n",
    "    }\n",
    "\n",
    "    for column, labels in custom_labels.items():\n",
    "        if column in X.columns:\n",
    "            # Create a mapping dictionary from numeric values to custom labels\n",
    "            label_mapping = {i: label for i, label in enumerate(labels)}\n",
    "            # Replace values in the column using the mapping\n",
    "            X[column] = X[column].replace(label_mapping)\n",
    "    return X\n",
    "\n",
    "\n",
    "# Assigning custom labels\n",
    "X = change_labels(X)\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBM - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       278\n",
      "           1       0.93      0.93      0.93       152\n",
      "\n",
      "    accuracy                           0.95       430\n",
      "   macro avg       0.94      0.94      0.94       430\n",
      "weighted avg       0.95      0.95      0.95       430\n",
      "\n",
      "EBM - AUC ROC: 0.9404\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Explainable Boosting Classifier model\n",
    "ebm_model = ExplainableBoostingClassifier(random_state=42)\n",
    "ebm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Generating predictions and probabilities on the test set\n",
    "Y_pred = ebm_model.predict(X_test)\n",
    "Y_pred_proba = ebm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Model evaluation\n",
    "print(\"EBM - Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(f\"EBM - AUC ROC: {roc_auc_score(Y_test, Y_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "ebm_model = ExplainableBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    \"max_bins\": [128, 256, 512],  # Number of bins for discretization\n",
    "    \"max_interaction_bins\": [32, 64, 128],  # Number of bins for interactions\n",
    "    \"interactions\": [0, 10, 50],  # Number of interactions\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],  # Learning rate\n",
    "    \"min_samples_leaf\": [2, 10, 20],  # Minimum number of samples per leaf\n",
    "    \"max_leaves\": [3, 5, 10],  # Maximum number of leaves per tree\n",
    "}\n",
    "\n",
    "# Use GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ebm_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",  # Metric for evaluation\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1,  # Verbosity level\n",
    "    n_jobs=-1,  # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best AUC score\n",
    "print(\"Best AUC score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_ebm_model = grid_search.best_estimator_\n",
    "Y_pred = best_ebm_model.predict(X_test)\n",
    "Y_pred_proba = best_ebm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"EBM - Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(f\"EBM - AUC ROC: {roc_auc_score(Y_test, Y_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ebm_local = ebm_model.explain_local(X_test[:5], Y_test[:5])\n",
    "# show(ebm_local)\n",
    "\n",
    "ebm_global = ebm_model.explain_global()\n",
    "show(ebm_global)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimer-s-disease-prediction-oDGSe6K4-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
